"""
페니스톡 확장 후 다음 단계 안내
"""

print("=" * 100)
print("페니스톡 종목 확장 완료!")
print("=" * 100)

print(f"""
[완료된 작업]
✓ data_collector.py 업데이트 완료
✓ 백업 파일 생성: src/data_collector_backup.py
✓ 종목 수 증가: ~210개 -> 522개 (+312개)

[종목 확장 내역]
- OTC Markets 고거래량: 29개
- AI & 양자컴퓨팅 확장: 17개
- 바이오테크 임상시험 확장: 103개
- Recent IPO 2023-2025: 16개
- EV & 그린에너지 확장: 18개
- 크립토/블록체인 확장: 4개
- SPAC & De-SPAC: 15개
- 대마초 & 환각제 확장: 9개
총 211개 카테고리 추가 + 기존 중복 제거 = 순증 312개

[예상 효과]
[+] 학습 데이터 2-3배 증가 (215K -> 500K+ rows)
[+] 더 다양한 패턴 학습 (AI, 바이오, EV, 크립토 등)
[+] 모델 일반화 능력 향상
[+] 급등 케이스 증가 -> 예측 정확도 향상
[+] 특정 종목 편향 감소
[+] 더 많은 거래 기회 (월 7회 -> 15-20회 예상)

[다음 단계]
""")

print("\n" + "=" * 100)
print("[단계 1] 새로운 종목 데이터 다운로드")
print("=" * 100)

print("""
명령어: python download_3year_data.py

작업 내용:
- 522개 종목의 3년치 데이터 다운로드 (2022-01 ~ 2025-10)
- 기존 데이터와 병합
- 예상 데이터 크기: 500K-600K rows

예상 소요 시간:
- 네트워크 속도에 따라 1-3시간
- yfinance API rate limit 고려
- 일부 종목은 데이터 없을 수 있음 (필터링됨)

주의사항:
[!] 네트워크 연결 안정적이어야 함
[!] 중간에 중단되면 재시작 필요
[!] API rate limit 도달 시 대기 필요
""")

print("\n" + "=" * 100)
print("[단계 2] God 모델 재학습")
print("=" * 100)

print("""
명령어: python train_god_model.py

작업 내용:
- 확장된 데이터로 4개 모델 학습
  1. XGBoost Advanced
  2. LightGBM Advanced
  3. RandomForest Advanced
  4. GradientBoosting
- 115+ 피처 생성
- 앙상블 가중치 최적화

예상 소요 시간:
- 데이터 로딩: 5-10분
- 피처 생성: 10-20분
- 모델 학습: 2-4시간 (데이터 크기에 따라)
- 총 소요 시간: 3-5시간

예상 메모리 사용:
- 8-16GB RAM 필요
- SSD 권장

성능 예측:
- 기존 ROC-AUC: 0.9789
- 예상 ROC-AUC: 0.98-0.99 (데이터 증가로 향상 가능)
""")

print("\n" + "=" * 100)
print("[단계 3] 백테스트 및 성능 비교")
print("=" * 100)

print("""
명령어: python backtest_god_model.py

작업 내용:
- 2024-04 ~ 2025-10 백테스트
- 임계값별 성능 평가
- 기존 모델과 비교

비교 지표:
                    기존 (232종목)    신규 (522종목)    예상 개선
------------------------------------------------------------------------
50% 급등 성공률      73.5%           75-80%          +1.5-6.5%
전체 승률            75.7%           77-82%          +1.3-6.3%
평균 수익률          1,427%          1,200-1,600%    유지/개선
MDD                 -67.6%          -60~-70%        유사/개선
월 평균 거래         7.2회           15-20회         +2-3배

거래 기회 증가:
- 더 많은 종목 -> 더 많은 시그널
- 더 다양한 섹터 -> 리스크 분산
- 월 7회 -> 월 15-20회 예상
""")

print("\n" + "=" * 100)
print("[단계 4] 성능 검증")
print("=" * 100)

print("""
검증 항목:
1. Lookahead Bias 재확인
   - T일 데이터 -> T+1일 거래 구조 유지

2. 과적합(Overfitting) 체크
   - Train/Test 성능 비교
   - 교차 검증 결과 확인

3. 섹터별 성능
   - AI/양자: 어떤 패턴?
   - 바이오테크: 임상시험 뉴스 반응?
   - EV: 정책 뉴스 반응?
   - 크립토: 비트코인 상관관계?

4. 리스크 관리
   - 새로운 MDD 확인
   - 최대 연속 손실 확인
   - 손실 분포 분석
""")

print("\n" + "=" * 100)
print("[단계 5] 실전 적용")
print("=" * 100)

print("""
준비 사항:
1. 최신 데이터로 예측 스크립트 실행
   - predict_current_signals.py 수정 필요

2. 임계값 0.95 전략 유지 또는 조정
   - 더 많은 시그널로 0.90-0.95 혼합 전략 고려

3. 포트폴리오 크기 조정
   - 기존: TOP 3-5 종목
   - 신규: TOP 5-10 종목 (거래 기회 증가)

4. 섹터 분산
   - 한 섹터에 집중하지 않기
   - AI, 바이오, EV, 크립토 등 골고루 분산

5. 백테스트 결과 기반 조정
   - 새로운 성능 지표 확인 후 전략 조정
""")

print("\n" + "=" * 100)
print("지금 시작하시겠습니까?")
print("=" * 100)

print("""
옵션 1: 데이터 다운로드만 먼저 실행 (권장)
  -> python download_3year_data.py
  -> 1-3시간 소요
  -> 완료 후 학습 여부 결정

옵션 2: 데이터 다운로드 + 학습 자동 실행
  -> python download_3year_data.py && python train_god_model.py
  -> 4-8시간 소요 (오버나잇 권장)
  -> 아침에 결과 확인

옵션 3: 기존 모델 유지, 데이터만 확장
  -> python download_3year_data.py
  -> 나중에 여유있을 때 재학습

권장: 옵션 1 (데이터 다운로드 먼저)
""")

print("\n" + "=" * 100)
print("주의사항")
print("=" * 100)

print("""
[!] 데이터 다운로드 중 인터넷 연결 끊기지 않도록 주의
[!] 학습 중 컴퓨터 절전 모드 해제 (3-5시간 소요)
[!] 충분한 디스크 공간 확보 (10-20GB 권장)
[!] 백그라운드 작업 최소화 (메모리 부족 방지)
[!] 기존 모델 백업 확인 (자동으로 models_backup/ 생성됨)

성공 조건:
[+] 안정적인 네트워크
[+] 충분한 메모리 (8GB+ 권장)
[+] 충분한 시간 (4-8시간)
[+] 인내심 (종목이 2.5배 증가했으니 시간도 2-3배)
""")

print("\n" + "=" * 100)
print("요약")
print("=" * 100)

print("""
✓ 종목 확장 완료: 210개 -> 522개
✓ 다음: 데이터 다운로드 (1-3시간)
✓ 그 다음: 모델 재학습 (3-5시간)
✓ 마지막: 백테스트 & 성능 비교

예상 최종 결과:
- 더 많은 거래 기회 (월 7회 -> 15-20회)
- 향상된 일반화 능력
- 다양한 섹터 커버리지
- 더 정확한 예측 (데이터 2-3배 증가)

준비되셨으면 다음 명령어 실행:
  python download_3year_data.py
""")

print("=" * 100)
